{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa14af5e-15da-48e1-8890-4ae95becebca",
   "metadata": {},
   "source": [
    "## PageRank Spark Example (Interactive)\n",
    "\n",
    "In order to run PySpark code in an interactive Jupyter notebook on Midway 3, we need to do the following:\n",
    "\n",
    "First, we will need to set up our environment on Midway 3 such that typing `pyspark` will automatically launch a Jupyter Lab server for us. Specifically, we should edit our .bashrc file from a Midway 3 login node using `nano`:\n",
    "\n",
    "```\n",
    "nano ~/.bashrc\n",
    "```\n",
    "\n",
    "Once the `nano` editor has opened, add the following lines to the bottom of your .bashrc file to configure PySpark to work with the version of Anaconda we've been using in the class, and also configure pyspark to launch a Jupyter Lab server automatically. Note that we are `echo`-ing the Host IP address so that we can use this information for port forwarding to our local machine later on.\n",
    "\n",
    "```\n",
    "export PYSPARK_PYTHON=/software/python-anaconda-2022.05-el8-x86_64/bin/python3\n",
    "export PYSPARK_DRIVER_PYTHON=\"jupyter\"\n",
    "\n",
    "# Display Host IP at start of each session so can copy for interactive sessions\n",
    "HOST_IP=`/sbin/ip route get 8.8.8.8 | awk '{print $7;exit}'`\n",
    "echo $HOST_IP\n",
    "export PYSPARK_DRIVER_PYTHON_OPTS=\"lab --no-browser --ip=$HOST_IP --port=8888\"\n",
    "export XDG_RUNTIME_DIR=''\n",
    "```\n",
    "\n",
    "Save and exit your .bashrc file. Then, run:\n",
    "\n",
    "```\n",
    "source ~/.bashrc\n",
    "```\n",
    "\n",
    "After you've done this once, you no longer need to perform this step again. Your environment is ready to go!\n",
    "\n",
    "---\n",
    "\n",
    "To run this notebook in interactive mode, enter into an `sinteractive` session (using relevant `sbatch` commands; here, requesting the same resources as in the `pagerank.sbatch` script in this directory for one hour):\n",
    "\n",
    "```\n",
    "sinteractive --time=01:00:00 --nodes=1 --ntasks=8 --mem=40G --partition=caslake --account=macs40123\n",
    "```\n",
    "\n",
    "Once you have entered into the interactive session, you will see your host IP printed above the command prompt (this is what we requested to happen when your `~/.bashrc` file is loaded). This should be a series of numbers and periods that looks like `10.50.250.12` (or any other series of numbers). Copy this IP address so that we can use it to for port forwarding below. \n",
    "\n",
    "Then load your modules and launch your PySpark Jupyter server with the same Slurm parameters provided to `spark-submit` in an `sbatch` script (here, activating the GraphFrames Spark package for use in the PySpark Jupyter Lab session):\n",
    "\n",
    "```\n",
    "module load python/anaconda-2022.05 spark/3.3.2\n",
    "pyspark --total-executor-cores 8 --executor-memory 5G --jars /project/macs40123/spark-jars/graphframes-0.8.3-spark3.4-s_2.12.jar\n",
    "```\n",
    "\n",
    "In a local terminal window, [follow the RCC instructions to forward the port of your remote Jupyter Server to your local port](https://rcc-uchicago.github.io/user-guide/software/apps-and-envs/python/#running-jupyter-notebooks) (step 4). For instance, given the above setup, if the host IP that you copied was `10.50.250.12`, you would run the following in your local terminal to forward to your local machine:\n",
    "\n",
    "```\n",
    "ssh -NL 8888:10.50.250.12:8888 <your-CNetID>@midway3.rcc.uchicago.edu\n",
    "```\n",
    "\n",
    "Note that once you log in, nothing will appear on your screen (this is expected given the `-N` flag). As long as you keep this local terminal window open, your remote content on port 8888 will be forwarded to your local port 8888. After logging in, you will be able to open the Jupyter Server URL `http://127.0.0.1:8888/?token=....` (printed out when you launched the server in your remote terminal window), or equivalently, `localhost:8888/?token=....` in the browser on your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "212d18bf-9fad-4aa5-9769-25e65443d689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| id|inDegree|\n",
      "+---+--------+\n",
      "|  b|       2|\n",
      "|  c|       1|\n",
      "+---+--------+\n",
      "\n",
      "+---+------------------+\n",
      "| id|          pagerank|\n",
      "+---+------------------+\n",
      "|  c|1.8994109890559092|\n",
      "|  b|1.0905890109440908|\n",
      "|  a|              0.01|\n",
      "+---+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# note that you must install the `graphframes` Python package from a login node\n",
    "# in order to run the code below, via the following commands:\n",
    "# module load python spark\n",
    "# pip install --user graphframes\n",
    "from pyspark.sql import SparkSession\n",
    "from graphframes import *\n",
    "\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"pagerank\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Create a Vertex DataFrame with unique ID column \"id\"\n",
    "v = spark.createDataFrame([\n",
    "  (\"a\", \"Alice\", 34),\n",
    "  (\"b\", \"Bob\", 36),\n",
    "  (\"c\", \"Charlie\", 30),\n",
    "], [\"id\", \"name\", \"age\"])\n",
    "\n",
    "# Create an Edge DataFrame with \"src\" and \"dst\" columns\n",
    "e = spark.createDataFrame([\n",
    "  (\"a\", \"b\", \"friend\"),\n",
    "  (\"b\", \"c\", \"follow\"),\n",
    "  (\"c\", \"b\", \"follow\"),\n",
    "], [\"src\", \"dst\", \"relationship\"])\n",
    "\n",
    "# Create a GraphFrame\n",
    "g = GraphFrame(v, e)\n",
    "\n",
    "# Query: Get in-degree of each vertex.\n",
    "g.inDegrees.show()\n",
    "\n",
    "# Run PageRank algorithm, and show results.\n",
    "results = g.pageRank(resetProbability=0.01, maxIter=20)\n",
    "results.vertices.select(\"id\", \"pagerank\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
